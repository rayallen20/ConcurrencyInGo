# Concurrency In Go

## 第3章 GO语言并发组件

### sync包

`sync`包包含了对低级别内存访问同步最有用的并发原语.这些操作的用处主要体现在一些比较小的作用域中,例如`struct`.你可以自行决定何时进行内存访问同步.

### WaitGroup

**当你不关心并发操作的结果,或者你有其他方法来收集并发操作的结果时,`WaitGroup`是等待一组并发操作完成的好方法**.如果这两个条件都不满足,则建议使用`channel`和`select`语句.

使用`WaitGroup`等待goroutine完成的基本示例:

```go
package main

import (
	"fmt"
	"sync"
	"time"
)

func main() {
	var wg sync.WaitGroup

	wg.Add(1)
	go func() {
		defer wg.Done()
		fmt.Println("1st goroutine sleeping...")
		time.Sleep(1)
	}()

	wg.Add(1)
	go func() {
		defer wg.Done()
		fmt.Println("2nd goroutine sleeping...")
		time.Sleep(1)
	}()

	wg.Wait()
	fmt.Println("All goroutines complete.")
}
```

第12行和第19行:`wg.Add(1)`.此处调用`Add`方法并传入参数1,表示1个goroutine开始了

第14行和第21行:`defer wg.Done()`.使用`defer`关键字来确保goroutine退出之前,调用`Done`方法向`WaitGroup`表明goroutine已经退出

第26行:`wg.Wait()`.`Wait`方法将阻塞main goroutine.直到所有的goroutine表明它们已经退出

注:这段代码中是存在竞争条件的,因为我们无法保证这2个goroutine运行的先后顺序.

运行结果:

结果1:

```
go run waitGroupDemo.go
1st goroutine sleeping...
2nd goroutine sleeping...
All goroutines complete.
```

结果2:

```
go run waitGroupDemo.go
2nd goroutine sleeping...
1st goroutine sleeping...
All goroutines complete.
```

你可以把`WaitGroup`视为一个并发安全的计数器:调用`Add`方法增加计数,调用`Done`方法减少计数.调用`Wait`方法会阻塞并等待计数器归零.

注意:**`Add`方法的调用是在gorutine之外完成的.如果不这样做,我们就会映入一个数据竞争条件.因为我们没有对goroutine做任何调度顺序上的保证.这就意味着我们可能在任何一个goroutine开始之前触发对`Wait`的调用**.如果将调用`Add`方法的代码添加到goroutine的闭包中,那么对`Wait`的调用可能会直接返回,而且不会阻塞,因为对`Add`的调用没有发生.

通常情况下,都要尽可能地和要跟踪的goroutine就近且成对的调用`Add`方法,但有时会调用1次`Add`方法来跟踪一组goroutine.通常在循环之前执行这种操作:

```go
package main

import (
	"fmt"
	"sync"
)

func main() {
	hello := func(wg *sync.WaitGroup, id int) {
		defer wg.Done()
		fmt.Printf("Hello from %v!\n", id)
	}

	const numGreeters = 5
	var wg sync.WaitGroup

	wg.Add(numGreeters)
	for i := 0; i < numGreeters; i++ {
		go hello(&wg, i + 1)
	}

	wg.Wait()
}
```

注:同样的,此处我们也没有办法保证循环中多个goroutine的执行顺序.所以这段代码的运行结果也是有多种可能性的.

运行结果:

结果1:

```
go run oneAddMultiGroutine.go
Hello from 5!
Hello from 4!
Hello from 2!
Hello from 1!
Hello from 3!
```

结果2:

```
go run oneAddMultiGroutine.go
Hello from 5!
Hello from 2!
Hello from 4!
Hello from 1!
Hello from 3!

```

### 互斥锁与读写锁

mutex这个单词本身就是"互斥"的意思,即"mutual exclusion"的意思.`Mutex`提供了一种并发安全的方式,用来表达对共享资源的独占.

例:2个goroutine试图增加和减少一个同样的变量,它们使用`Mutex`互斥锁来同步访问:

```go
package main

import (
	"fmt"
	"sync"
)

func main() {
	var count int
	var lock sync.Mutex

	increment := func() {
		lock.Lock()
		defer lock.Unlock()
		count++
		fmt.Printf("Incrementing: %d\n", count)
	}

	decrement := func() {
		lock.Lock()
		defer lock.Unlock()
		count--
		fmt.Printf("Decrementing: %d\n", count)
	}

	// 增量
	var arithmetic sync.WaitGroup
	for i := 0; i <= 5; i++ {
		arithmetic.Add(1)
		go func() {
			defer arithmetic.Done()
			increment()
		}()
	}

	// 减量
	for i := 0; i <= 5; i++ {
		arithmetic.Add(1)
		go func() {
			defer arithmetic.Done()
			decrement()
		}()
	}

	arithmetic.Wait()
	fmt.Println("Arithmetic complete.")
}
```

注:本例中同样含有竞争条件."增量"和"减量"这两个循环创建了总共10个goroutine,没有任何条件来保证这10个goroutine的执行顺序(当然本例中也不需要保证)

由于存在竞争条件,所以运行结果并不确定:

结果1:

```
go run mutexDemo.go 
Incrementing: 1
Decrementing: 0
Decrementing: -1
Decrementing: -2
Decrementing: -3
Decrementing: -4
Decrementing: -5
Incrementing: -4
Incrementing: -3
Incrementing: -2
Incrementing: -1
Incrementing: 0
Arithmetic complete.
```

结果2:

```
go run mutexDemo.go
Incrementing: 1
Decrementing: 0
Incrementing: 1
Incrementing: 2
Incrementing: 3
Incrementing: 4
Incrementing: 5
Decrementing: 4
Decrementing: 3
Decrementing: 2
Decrementing: 1
Decrementing: 0
Arithmetic complete.
```

第13行和第20行:`lock.Lock()`.请求对临界区的独占(本例中即为`count`).此时`count`变量由互斥锁保护

第14行和第21行:`defer lock.Unlock()`.表示已经完成了对临界区锁定的保护

注意:在这个例子中,我们总是在`defer`语句中调用`Unlock`方法.这是一种非常常见的做法.这种做法的好处在于,即使出现了`panic`,对`Unlock`方法的调用也能执行.否则有可能因为`panic`导致未能调用`Unlock`方法,进而导致程序陷入死锁.

**加锁的部分通常是程序的性能瓶颈,因为进入和退出一个临界区的成本较高.所以人们会尽量减少锁涉及的范围**.

**有可能出现的一种情况是:多个并发进程之间共享的内存,并不是所有并发进程都需要读写这段内存**.此时可以使用另一个类型的互斥对象:`sync.RWMutex`

`sync.RWMutex`和`Mutex`在概念上相同:它保护对内存的访问,但是`RWMutex`让你对内存有了更多的控制方式.除非有其他事物持有一个写锁,否则可以有任意数量的读锁可以被授予.换言之,只要没有别的东西占用写操作,则任意数量的读取者均可进行读取操作.

例:本例中有一个生产者,它并不像代码中创建的众多消费者那样活跃,同时有多个观察者:

```go
package main

import (
	"fmt"
	"math"
	"os"
	"sync"
	"text/tabwriter"
	"time"
)

func main() {
	producer := func(wg *sync.WaitGroup, lock sync.Locker) {
		defer wg.Done()
		for i := 5; i > 0; i-- {
			lock.Lock()
			lock.Unlock()
			time.Sleep(1)
		}
	}

	observer := func(wg *sync.WaitGroup, lock sync.Locker) {
		defer wg.Done()
		lock.Lock()
		defer lock.Unlock()
	}

	test := func(count int, mutex, rwMutex sync.Locker) time.Duration {
		var wg sync.WaitGroup
		wg.Add(count + 1)
		beginTestTime := time.Now()
		go producer(&wg, mutex)

		for i := count; i > 0; i-- {
			go observer(&wg, rwMutex)
		}
		wg.Wait()

		return time.Since(beginTestTime)
	}

	tw := tabwriter.NewWriter(os.Stdout, 0, 1, 3, ' ', 0)
	defer tw.Flush()

	var rwMutex sync.RWMutex
	fmt.Fprintf(tw, "Readers\tMutex\tRWMutex\n")

	for i := 0; i < 20; i++ {
		count := int(math.Pow(2, float64(i)))
		fmt.Fprintf(
			tw,
			"%d\t%v\t%v\n",
			count,
			test(count, &rwMutex, rwMutex.RLocker()),
			test(count, &rwMutex, &rwMutex),
			)
	}
}
```

TODO:此处第46行原文为`fmt.Fprintf(tw, "Readers\tRWMutex\tMutex\n")`,但我自己根据最后对`test()`的调用传参认为写错了.否则本机上无法跑出来书中类似的结果.

- 第13行:`producer := func(wg *sync.WaitGroup, lock sync.Locker)`.`producer`函数的第2个参数为`sync.Locker`类型.该类型是一个接口,该接口有2个方法:`Lock`和`Unlock`.`Mutex`和`RWMutex`均为该接口的实现
- 第18行:`time.Sleep(1)`.让`producer`等待1s,使它比`observer`的goroutine更不活跃
- 第54行:`test(count, &rwMutex, rwMutex.RLocker())`.其中`rwMutex.RLocker()`方法返回的是一个互斥锁

运行结果:

```
 go run RWMutexDemo.go
Readers   Mutex          RWMutex
1         36.096µs       3.342µs
2         5.879µs        16.737µs
4         46.547µs       22.607µs
8         11µs           6.003µs
16        31.391µs       10.168µs
32        82.856µs       56.647µs
64        112.233µs      54.36µs
128       73.295µs       95.135µs
256       115.625µs      257.648µs
512       165.215µs      132.673µs
1024      264.336µs      284.229µs
2048      515.191µs      458.396µs
4096      1.11502ms      1.048978ms
8192      2.085466ms     1.890802ms
16384     4.164689ms     3.75388ms
32768     8.509742ms     7.34518ms
65536     17.303309ms    14.453378ms
131072    34.231474ms    29.256701ms
262144    69.400169ms    57.906907ms
524288    156.629426ms   116.887957ms
```

在这个例子中,我们减少了临界区的范围.可以看到读写锁比互斥锁有性能优势.但这同样要取决于你在临界区内做了什么操作.通常建议在逻辑上合理的情况下使用`RWMutex`而非`Mutex`.

### cond

先来看`sync.Cond`的文档:

```go

// Cond implements a condition variable, a rendezvous point
// for goroutines waiting for or announcing the occurrence
// of an event.
//
// Each Cond has an associated Locker L (often a *Mutex or *RWMutex),
// which must be held when changing the condition and
// when calling the Wait method.
//
// A Cond must not be copied after first use.
type Cond struct {
	noCopy noCopy

	// L is held while observing or changing the condition
	L Locker

	notify  notifyList
	checker copyChecker
}
```

`sync.Cond`实现了一个条件变量,是多个goroutine的交汇点.这些goroutine正在等待或宣布一个事件的发生.

在这个定义中,"事件"是指2个或者更多的goroutine之间的任何信号,这个信号仅仅指示事件发生,不包含任何其他信息.通常情况下,你可能想要在收到来自某个goroutine的信号前,令当前goroutine处于等待状态.

如果不使用`sync.Cond`,那就要使用无限循环来解决:

```go
for conditionTrue == false {
	// 等待
}
// 工作内容代码
```

但是,这种方式会消耗一个CPU核心的所有周期.可以引入`time.Sleep`来改善:

```go
for conditionTrue() == false {
	// 等待
	time.Sleep(1 * time.Millisecond)
}
// 工作内容代码
```


这样更好,但它仍然是低效的,而且你必须弄清楚要等待多久:太长,会人为地降低性能;太短,会不必要地消耗太多的CPU时间.如果有一种方怯可以让goroutine有效地等待,直到它发出信号并检查它的状态,那就更好了.这正是`sync.Cond`类型为我们所做的.使用`sync.Cond`,我们可以这样编写前面例子的代码:

**如果有一种方法,可以让goroutine"更有效地休眠",直到该goroutine被唤醒,并让该goroutine能够检查自身的状态,将会更好.**

使用`sync.Cond`,这个例子可以改写为:

```go
c := sync.NewCond(&sync.Mutex{})
c.L.Lock()
for conditionTrue == false {
	c.Wait()
}
// 正常工作代码
c.L.Unlock()
```

第1行:`c := sync.NewCond(&sync.Mutex{})`.`NewCond()`函数要求传入一个接口`sync.Locker`的实现.该参数赋予了`sync.Cond`能够以一种并发安全的方式与其他goroutine协调的能力.

第2行:`c.L.Lock()`.这一步是必要的,因为后续调用`Wait()`方法会自动执行`c.L.Unlock()`并暂停该goroutine.(实际上解锁后是将该goroutine放入了一个等待通知的队列中,然后等待信号的到来)

第4行:`c.Wait()`.等待通知直到条件满足为止.这是一个阻塞通信,goroutine将会被暂停.

第7行:`c.L.Unlock()`.此处执行解锁是必要的.因为在`Wait()`方法中,将该goroutine放入等待通知的队列中之后等待信号到来.当信号到来时,会调用`c.L.Lock()`,再次尝试获取锁.所以完成工作后,需要再调用一次解锁.

这种方法的效率更高.但需要注意的是:调用`Wait()`不仅仅会阻塞.它将会暂停当前的goroutine,将当前goroutine加入到一个等待通知的队列中去,并允许其他goroutine在OS线程上运行.当你调用`Wait()`方法时,还会发生一些其他事情:进入`Wait()`后,首先会调用`Cond.Locker.Unlock()`方法;退出`Wait()`前,会调用`Cond.Locker.Lock()`方法.这实际上是`Wait()`方法的副作用:**从代码上来看,我们在等待条件满足期间,一直持有这个锁.但事实并非如此.**当你查看代码时,你需要留意这一点.

让我们来扩展这个例子,以便学习等待信号的goroutine和发送信号的goroutine该怎么写.假设我们有一个固定长度为2的队列,同时还有10个元素,我们想要将这些元素推送到队列中.我们希望队列中有空间时能够立刻得到通知,以便能够将元素推送至队列中.让我们尝试使用`sync.Cond`来管理这种调度:

```go
package main

import (
	"fmt"
	"sync"
	"time"
)

func main() {
	c := sync.NewCond(&sync.Mutex{})
	queue := make([]interface{}, 0, 10)

	// 移除元素 用于模拟发射信号一方的goroutine
	removeFromQueue := func(delay time.Duration) {
		time.Sleep(delay)
		c.L.Lock()
		queue = queue[1:]
		fmt.Println("Removed from queue")
		c.L.Unlock()
		c.Signal()
	}

	// 推送元素 用于模拟等待并接收信号一方的goroutine
	for i := 0; i < 10; i++ {
		c.L.Lock()
		for len(queue) == 2 {
			c.Wait()
		}
		fmt.Println("Adding to queue")
		queue = append(queue, struct{}{})
		go removeFromQueue(1 * time.Second)
		c.L.Unlock()
	}
}
```

第10行:`c := sync.NewCond(&sync.Mutex{})`.此处我们选用互斥锁`sync.Mutex`作为Locker来创建`sync.Cond`

第11行:`queue := make([]interface{}, 0, 10)`.创建一个长度为0的切片.由于我们知道最终会添加10个元素,因此我们将容量设定为10.

第25行:`c.L.Lock()`.进入临界区,以便后续能够独占`queue`的访问权.

第26行:`for len(queue) == 2`.检查队列的长度,以便确认是否需要等待.这个判断很重要,因为`removeFromQueue`是异步执行的,所以在这个场景下,即使`main goroutine`收到了一个信号,也并不一定是标识队列长度为2的信号,或许是标识其他事件的信号.因此需要条件判断.而`if`又做不到重复判断,所以要使用`for`.

第27行:`c.Wait()`.这行代码将会阻塞`main goroutine`,直到接收到信号为止.

第31行:`go removeFromQueue(1 * time.Second)`.创建一个新的goroutine,这个goroutine会在1s后将1个元素移出队列.

第32行:`c.L.Unlock()`.已经成功将一个元素推送进队列,不再需要对`queue`的独占访问权,退出临界区.

第16行:`c.L.Lock()`.进入临界区,以便独占`queue`的访问权.

第17行:移除切片头部并分配给第2个元素,以便模拟元素出队

第19行:`c.L.Unlock()`.已经成功移除一个元素,不再需要对`queue`的独占访问权,退出临界区.

第20行:`c.Signal()`.发出信号,通知**1个**处于等待状态的goroutine可以进行下一步操作了.

这段程序的输出:

```
go run condDemo.go 
Adding to queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
Removed from queue
Adding to queue
```

程序成功将10个元素推送至队列中,并且会在最后两个被推送进队列的元素被删除之前退出.这段程序也会持续等待,直到至少有1个元素被写入队列为止.

在这个例子中,我们使用了一个新的方法`Signal()`.这是`sync.Cond`提供的两种通知方法之一,该方法用于通知在等待调用上阻塞的goroutine,告知goroutine条件已经被触发.在内部,运行时维护一个FIFO性质的队列,这个队列由等待信号发送的所有goroutine构成.`Signal()`方法用于寻找等待时间最长的goroutine,并向该goroutine发送信号;`Broadcast()`方法向所有处在等待状态的goroutine发送信号.**`Broadcast()`提供了一种同时与多个goroutine进行通信的解决方案.**我们可以通过`channel`轻松复刻`Signal()`的功能,但很难使用`channel`来复刻`Broadcast()`的功能.另外,`sync.Cond`比`channel`更加高效.

为了了解`Broadcast()`方法的使用,我们再来举一个例子.

假设此时我们正在创建一个带有按钮的GUI程序,该程序需要注册任意数量的函数,当点击该按钮时,所有函数都要被运行.这个场景就可以使用`Broadcast()`方法来通知所有已经注册的函数.

```go
package main

import (
	"fmt"
	"sync"
)

type Button struct {
	Clicked *sync.Cond
}

func main() {
	button := Button{Clicked: sync.NewCond(&sync.Mutex{})}

	subscribe := func(c *sync.Cond, fn func()) {
		var goroutineRunning sync.WaitGroup
		goroutineRunning.Add(1)
		go func() {
			goroutineRunning.Done()
			c.L.Lock()
			defer c.L.Unlock()
			c.Wait()
			fn()
		}()
		goroutineRunning.Wait()
	}

	var clickRegistered sync.WaitGroup
	clickRegistered.Add(3)

	subscribe(button.Clicked, func() {
		fmt.Println("Maximizing window.")
		clickRegistered.Done()
	})

	subscribe(button.Clicked, func() {
		fmt.Println("Displaying annoying dialog box!")
		clickRegistered.Done()
	})

	subscribe(button.Clicked, func() {
		fmt.Println("Mouse clicked.")
		clickRegistered.Done()
	})
	
	button.Clicked.Broadcast()
	clickRegistered.Wait()
}
```

第8-10行:`type Button struct {Clicked *sync.Cond}`.定义了一个`Button`类型.包含一个成员属性`Clicked`,其类型为`sync.Cond`的指针.这个成员属性是goroutine接收通知的关键条件.

第15行:`subscribe := func(c *sync.Cond, fn func())`.此处我们定义了一个比较简单的函数,这个函数允许我们自己注册的函数接收信号.每个被注册的函数都在自己的goroutine上运行,并且直到接收到信号为止,这个goroutine都不会退出.实际上`subscribe()`直到goroutine被确认运行为止,都不会退出.

TODO:此处是`subscribe()`会退出,而`subscribe()`创建的goroutine不会退出的意思吗?

第46行:此处给按钮点击事件设置了一个处理程序.这个程序反过来调用`sync.Cond.Broadcast()`,给所有被注册的函数都发送信号,以便让这些函数知道按钮被单击了(实际上更健壮的程序会先检查按钮是否已经被禁用).

第28行:`var clickRegistered sync.WaitGroup`.确保我们的程序在写入stdout之前不会退出.

第31-34行:模拟点击时最大化窗口

```go
subscribe(button.Clicked, func() {
	fmt.Println("Maximizing window.")
	clickRegistered.Done()
})
```

第36-39行:模拟显示对话框

```go
subscribe(button.Clicked, func() {
	fmt.Println("Displaying annoying dialog box!")
	clickRegistered.Done()
})
```

第41-44行:模拟鼠标点击

```go
subscribe(button.Clicked, func() {
	fmt.Println("Mouse clicked.")
	clickRegistered.Done()
})
```

程序运行结果:

```
go run condBroadcast.go
Mouse clicked.
Maximizing window.
Displaying annoying dialog box!
```

可以看到,通过调用`sync.Cond.Broadcast()`方法,3个自己注册的函数都运行了.

TODO:书中原文:如果不是`clickRegistered`的`sync.WaitGroup`,我们可以调用`button.Clicked.Broadcast()`多次,并且每次都调用3个处理程序.这是`channel`不太容易做到的.这也是使用`sync.Cond`的优势之一.

**和`sync`包中的大多数内容一样,`Cond`的使用最好被限制在一个紧凑的范围中,或者通过封装它,以便让它暴露在更大的范围内.**

### once

Q:以下代码输出什么?

```go
package main

import (
	"fmt"
	"sync"
)

func main() {
	var count int

	increment := func() {
		count++
	}

	var once sync.Once

	var increments sync.WaitGroup
	increments.Add(100)

	for i := 0; i < 100; i++ {
		go func() {
			defer increments.Done()
			once.Do(increment)
		}()
	}

	increments.Wait()
	fmt.Printf("count is %d\n", count)
}
```

程序运行结果:

```
go run onceDemo.go 
count is 1
```

顾名思义,`sync.Once`是一种类型,它在内部使用一些`sync`原语,以确保即使在不同的goroutine上,调用`Do()`方法传入的函数只执行一次.

看起来将多次调用1个函数但只执行1次的功能封装到标准库是一件很奇怪的事情.但事实上这种需求经常出现.我们来检查GO的标准库,看看GO本身使用这个原语的频率:

```
grep -ir sync.Once $(go env GOROOT)/src |wc -l
146
```

Q:以下代码输出什么?

```go
package main

import (
	"fmt"
	"sync"
)

func main() {
	var count int
	increment := func() { count++ }
	decrement := func() { count-- }

	var once sync.Once

	once.Do(increment)
	once.Do(decrement)

	fmt.Printf("count: %d\n", count)
}
```

```
go run onceDoOnlyRunOnce.go 
count: 1
```

原因:**`sync.Once`只计算`Do`被调用的次数,而非调用传入`Do()`方法的唯一函数的次数.**

`sync.Once`应该和被用于调用的函数紧密耦合.此处再次看到`sync`包内如何在1个紧凑的范围内发挥最佳效果.**建议通过将`sync.Once`包装在一个小的代码块中来形式化这种耦合.这种代码块可以是一个小函数,也可以是一个结构体.**

Q:以下代码会发生什么?

```go
package main

import "sync"

func main() {
	var onceA, onceB sync.Once

	var initB func()

	initA := func() { onceB.Do(initB) }
	initB = func() { onceA.Do(initA) }
	onceA.Do(initA)
}
```

```
go run onceDoDeadlock.go 
fatal error: all goroutines are asleep - deadlock!
```

再重复一次死锁的定义:所有并发进程彼此等待

这段代码中,直到第12行处对`onceA.Do()`方法的调用完毕为止,
第11行处对`onceA.Do()`方法的调用都不会执行.而第12行处对`onceA.Do()`方法的调用又需要第11行处`onceA.Do()`方法的调用执行完毕才能返回.因此第11行和第12行彼此等待,导致死锁.

### Pool

`sync.Pool`是对象池模式的并发安全实现.在较高的层次上,**池模式是一种创建和提供固定数量可用对象的方式.**它通常用于约束创建资源昂贵的事物(如DB连接),以便只创建固定数量的实例,GO的`sync.Pool`可以被多个goroutine安全地使用.

`sync.Pool`的主接口是它的`Get()`方法.该方法被调用时,先检查池中是否有可用的实例,如果有则直接返回给调用者;如果没有,则创建一个新的实例(调用成员属性`New`).

使用完成后,调用者调用`Put()`方法把工作的实例归还到池中,以供其他进程使用.

Q:以下代码会发生什么?

```go
package main

import (
	"fmt"
	"sync"
)

func main() {
	myPool := &sync.Pool{
		New: func() interface{} {
			fmt.Println("Creating new instance.")
			return struct{}{}
		},
	}

	myPool.Get()
	instance := myPool.Get()
	myPool.Put(instance)
	myPool.Get()
}
```

```
go run poolDemo.go
Creating new instance.
Creating new instance.
```

第16行:调用`sync.Pool.Get()`.此时池中没有实例可供使用,故调用`sync.Pool.New`,创建一个实例给调用者.此处`sync.Pool.New`第1次被调用;此时池中的可用实例数量为0

第17行:调用`sync.Pool.Get()`.此时池中仍旧没有实例可供使用,故再次调用调用`sync.Pool.New`,再创建一个实例给调用者.此处`sync.Pool.New`第2次被调用;此时池中的可用实例数量为0

第18行:调用者将之前获得的实例放回池中.;此时池中的可用实例数量为1

第19行:调用`sync.Pool.Get()`,`sync.Pool`将池中的可用实例分配给调用者

故打印2次

Q:为什么要使用调用`sync.Pool`,而不是在运行实例化对象呢?GO语言是有GC的,因此实例化的对象将被自动清理,使用`sync.Pool`的意义何在?

```go
package main

import (
	"fmt"
	"sync"
)

func main() {
	var numCalcCreated int
	calcPool := &sync.Pool{
		New: func() interface{} {
			numCalcCreated += 1
			mem := make([]byte, 1024)
			return &mem
		},
	}

	// 用4KB初始化pool
	calcPool.Put(calcPool.New)
	calcPool.Put(calcPool.New)
	calcPool.Put(calcPool.New)
	calcPool.Put(calcPool.New)

	const numWorkers = 1024 * 1024
	var wg sync.WaitGroup
	wg.Add(numWorkers)
	for i := numWorkers; i > 0; i-- {
		go func() {
			defer wg.Done()
			mem := calcPool.Get()
			// 此处假定在内存中做了某些速度较快的操作
			defer calcPool.Put(mem)
		}()
	}

	wg.Wait()
	fmt.Printf("%d calculators were created\n", numCalcCreated)
}
```

```
go run poolAndInstantiation.go
7 calculators were created
```

```
go run poolAndInstantiation.go
6 calculators were created
```

在这个场景下,如果给每一个goroutine都实例化一个mem,那么这段程序将消耗1个G的内存.而使用`sync.Pool`,可以保证实例被先运行的goroutine使用完后,归还给`sync.Pool`,让后运行的goroutine继续使用.因此减少了内存开销.

`sync.Pool`的另一种常见使用场景:使用`sync.Pool`尽可能快地将预先分配的对象缓存加载启动.即:通过预先加载获取对另一个对象的引用,来减少调用者的时间消耗(加载一个对象的引用所需的时间,一定是比创建一个对象所需的时间要短的).**在编写高吞吐量网络服务器时,这是非常常见的手段.**

- step1. 编写一个模拟创建服务连接的函数

```go
// connectToService 本函数用于模拟创建一个到服务连接
// 此处故意让创建连接这个过程消耗较长的时间
func connectToService() interface{} {
	time.Sleep(time.Second)
	return struct{}{}
}
```

- step2. 编写一个网络处理函数,每次调用该函数,仅允许1个连接

```go
// startNetworkDaemon 本函数是一个网络处理程序 每次调用本函数 仅允许1个连接
func startNetworkDaemon() *sync.WaitGroup {
	var wg sync.WaitGroup
	// 为简化基准测试 此处每次仅允许1个连接
	wg.Add(1)

	go func() {
		server, err := net.Listen("tcp", "localhost:8090")
		if err != nil {
			log.Fatalf("can not listen: %v\n", err)
		}
		defer server.Close()

		wg.Done()

		for {
			conn, err := server.Accept()
			if err != nil {
				log.Printf("can not accept connection: %v\n", err)
				continue
			}

			connectToService()
			fmt.Fprintln(conn, "")
			conn.Close()
		}
	}()

	return &wg
}
```

- step3. 编写基准测试函数

```go
func init() {
	daemonStarted := startNetworkDaemon()
	daemonStarted.Wait()
}

func BenchmarkNetworkRequest(b *testing.B) {
	for i := 0; i < b.N; i++ {
		conn, err := net.Dial("tcp", "localhost:8090")
		if err != nil {
			b.Fatalf("can not dial host: %v\n", err)
		}
		
		if _, err := ioutil.ReadAll(conn); err != nil {
			b.Fatalf("can not read: %v\n", err)
		}
		conn.Close()
	}
}
```

完整代码如下:

```go
package main

import (
	"fmt"
	"io/ioutil"
	"log"
	"net"
	"sync"
	"testing"
	"time"
)

func main() {

}

// connectToService 本函数用于模拟创建一个到服务连接
// 此处故意让创建连接这个过程消耗较长的时间
func connectToService() interface{} {
	time.Sleep(time.Second)
	return struct{}{}
}

// startNetworkDaemon 本函数是一个网络处理程序 每次调用本函数 仅允许1个连接
func startNetworkDaemon() *sync.WaitGroup {
	var wg sync.WaitGroup
	// 为简化基准测试 此处每次仅允许1个连接
	wg.Add(1)

	go func() {
		server, err := net.Listen("tcp", "localhost:8090")
		if err != nil {
			log.Fatalf("can not listen: %v\n", err)
		}
		defer server.Close()

		wg.Done()

		for {
			conn, err := server.Accept()
			if err != nil {
				log.Printf("can not accept connection: %v\n", err)
				continue
			}

			connectToService()
			fmt.Fprintln(conn, "")
			conn.Close()
		}
	}()

	return &wg
}

func init() {
	daemonStarted := startNetworkDaemon()
	daemonStarted.Wait()
}

func BenchmarkNetworkRequest(b *testing.B) {
	for i := 0; i < b.N; i++ {
		conn, err := net.Dial("tcp", "localhost:8090")
		if err != nil {
			b.Fatalf("can not dial host: %v\n", err)
		}

		if _, err := ioutil.ReadAll(conn); err != nil {
			b.Fatalf("can not read: %v\n", err)
		}
		conn.Close()
	}
}
```

执行基准测试:

```
go test -benchtime=10s -bench=.
goos: darwin
goarch: amd64
pkg: code/chapter3/21-poolPreload
cpu: Intel(R) Core(TM) i7-7820HQ CPU @ 2.90GHz
BenchmarkNetworkRequest-8             10        1001994218 ns/op
PASS
ok      code/chapter3/21-poolPreload    11.150s
```

可以看到,大约是1E9 ns/op

使用`sync.Pool`来改进虚拟服务:

- step1. 编写一个模拟创建服务连接的函数

```go
// connectToService 本函数用于模拟创建一个到服务连接
// 此处故意让创建连接这个过程消耗较长的时间
func connectToService() interface{} {
	time.Sleep(time.Second)
	return struct{}{}
}
```

- step2. 编写一个在池中预创建10个连接的函数

```go
// warmServiceConnCache 本函数用于在池中预创建10个连接
func warmServiceConnCache() *sync.Pool {
	p := &sync.Pool{
		New: connectToService,
	}
	
	// 预创建10个连接放入池中
	for i := 0; i < 10; i++ {
		p.Put(p.New)
	}
	return p
}
```

- step3. 编写一个处理网络请求的函数

```go
// startNetworkDaemon 本函数是一个网络处理程序 每次调用本函数 仅允许1个连接
// 但这个连接是从池中取出的 并非是请求时创建的
func startNetworkDaemon() *sync.WaitGroup {
	var wg sync.WaitGroup
	wg.Add(1)
	go func() {
		connPool := warmServiceConnCache()
		server, err := net.Listen("tcp", "localhost:8090")
		if err != nil {
			log.Fatalf("can not listen: %v\n", err)
		}
		defer server.Close()
		
		wg.Done()
		
		for {
			conn, err := server.Accept()
			if err != nil {
				log.Printf("can not accept connection: %v\n", err)
				continue
			}
			
			serviceConn := connPool.Get()
			fmt.Fprintln(conn, "")
			connPool.Put(serviceConn)
			conn.Close()
		}
	}()
	
	return &wg
}
```

- step4. 编写基准测试函数

```go
func init() {
	daemonStarted := startNetworkDaemon()
	daemonStarted.Wait()
}

func BenchmarkNetworkRequest(b *testing.B) {
	for i := 0; i < b.N; i++ {
		conn, err := net.Dial("tcp", "localhost:8090")
		if err != nil {
			b.Fatalf("can not dial host: %v\n", err)
		}

		if _, err := ioutil.ReadAll(conn); err != nil {
			b.Fatalf("can not read: %v\n", err)
		}
		conn.Close()
	}
}
```

完整代码如下:

```go
package main

import (
	"fmt"
	"io/ioutil"
	"log"
	"net"
	"sync"
	"testing"
	"time"
)

func main() {

}

// connectToService 本函数用于模拟创建一个到服务连接
// 此处故意让创建连接这个过程消耗较长的时间
func connectToService() interface{} {
	time.Sleep(time.Second)
	return struct{}{}
}

// warmServiceConnCache 本函数用于在池中预创建10个连接
func warmServiceConnCache() *sync.Pool {
	p := &sync.Pool{
		New: connectToService,
	}

	// 预创建10个连接放入池中
	for i := 0; i < 10; i++ {
		p.Put(p.New)
	}
	return p
}

// startNetworkDaemon 本函数是一个网络处理程序 每次调用本函数 仅允许1个连接
// 但这个连接是从池中取出的 并非是请求时创建的
func startNetworkDaemon() *sync.WaitGroup {
	var wg sync.WaitGroup
	wg.Add(1)
	go func() {
		connPool := warmServiceConnCache()
		server, err := net.Listen("tcp", "localhost:8090")
		if err != nil {
			log.Fatalf("can not listen: %v\n", err)
		}
		defer server.Close()

		wg.Done()

		for {
			conn, err := server.Accept()
			if err != nil {
				log.Printf("can not accept connection: %v\n", err)
				continue
			}

			serviceConn := connPool.Get()
			fmt.Fprintln(conn, "")
			connPool.Put(serviceConn)
			conn.Close()
		}
	}()

	return &wg
}

func init() {
	daemonStarted := startNetworkDaemon()
	daemonStarted.Wait()
}

func BenchmarkNetworkRequest(b *testing.B) {
	for i := 0; i < b.N; i++ {
		conn, err := net.Dial("tcp", "localhost:8090")
		if err != nil {
			b.Fatalf("can not dial host: %v\n", err)
		}

		if _, err := ioutil.ReadAll(conn); err != nil {
			b.Fatalf("can not read: %v\n", err)
		}
		conn.Close()
	}
}
```

执行基准测试:

```
go test -benchtime=10s -bench=.
goos: darwin
goarch: amd64
pkg: code/chapter3/22-poolPreload2
cpu: Intel(R) Core(TM) i7-7820HQ CPU @ 2.90GHz
BenchmarkNetworkRequest-8           5688           1962593 ns/op
PASS
ok      code/chapter3/22-poolPreload2   26.303s
```

可以看到,大约为2E6 ns/op.快了3个数量级.

以下2种场景适合使用Pool设计模式:

1. 当你的并发进程需要请求(创建)一个对象,但是在实例化之后很快就不再使用这个对象时
2. 在构造对象时对内存产生负面影响时

Pool设计模式不适用的场景:

1. 池中存储的对象不同质(在内存中的分配不是大致均匀的)时,从Pool中检索到所需要的对象的时间,可能比重新实例化这个对象花费的时间更多.简而言之,如果池中的对象在内存中的分配不均匀,则在池中检索的时间将大于实例化对象所需的时间

例如:假设你的程序需要随机和可变长度的切片,那么Pool将不会对你有多大帮助.

当使用Pool时的注意事项:

1. 当实例化`sync.Pool`时,使用`sync.Pool.New()`方法创建的元素,在调用时是线程安全的
2. 当从`sync.Pool.Get()`方法中获得实例时,不要假设你接收到的对象状态
3. 当用完一个从`sync.Pool`中取出的对象时,一定要调用`sync.Pool.Put()`方法将这个对象放回池中.否则无法复用这个实例.**通常情况下.这个操作用defer来完成**
4. Pool内的分布必须大致均匀