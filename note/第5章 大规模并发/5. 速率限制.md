# Concurrency In Go

## 第5章 大规模并发

### 速率限制

如果你曾经使用过API服务,你可能和速率限制做过斗争.速率限制用于限制资源在单位时间内被访问的次数.这里的资源可以认为是任何东西:API连接、磁盘读写、网络数据包、错误等.

你有没有想过为什么要在一个服务中设置速率限制?为什么不允许对系统进行无限制的访问?最明显的答案是通过对系统进行速率限制,可以避免你的系统被攻击.如果恶意用户可以以他们资源允许的速度上限访问你的系统,那他们可以做各种各样的事情.

例如,他们可以用日志消息或有效请求写满你的磁盘.如果你错误的配置了日志覆盖,他们甚至可以执行一些恶意操作,他们会发起足够数量的请求,直到将所有活动记录都被排除出日志,而这些活动记录最终将进入`/dev/null`.他们可以强制访问资源,或者进行DDoS攻击.关键点在于:**如果你不对系统进行速率限制,那么你将很难保证它的安全性**.

可能被恶意利用并不是应该进行速率限制的唯一原因.在分布式系统中,即使是合法用户,如果这些合法用户正在以足够大的量级执行操作或者他们执行的代码是有Bug的,也会降低整个系统的性能,进而对其他用户的使用造成影响.这甚至可能导致出现我们之前提到过的死亡螺旋.从产品的角度上来看,这是非常糟糕的!通常你是希望向用户提供一些关于系统性能方面的保障的,而每位用户被分配的性能是均衡的.如果每个用户都能够打破这个平衡,那无疑是非常糟糕的.用户的心智模型通常认为他们对系统的访问是隔离的,他们既不会影响到其他用户的访问,也不会被其他用户的访问所影响.如果打破了这种心智模型,用户会认为你的系统设计不良,并可能导致他们感到愤怒或离开.

即使只有1个用户,速率限制也是有用的.大部分场景下,我们的开发任务是针对常见的用例进行的,但是在不同的环境下,可能会有不同的表现.在复杂的系统(例如分布式系统)中,这种影响可能因为系统级联而放大,最终产生严重的、意想不到的后果.在高负载的环境下,你的系统可能会开始丢包,进而导致你的分布式数据库失去仲裁,进而停止接受写入,再进而导致当前请求失败,然后...你可以看到这是一件多么糟糕的事情.这种情况相当于系统在对自己进行一种DDoS攻击,这不是没有先例的!

****

##### 一个真实的案例

我曾经参与过一个分布式系统的开发,该系统通过启动新进程的方式来处理并行工作(这使得系统可以水平扩展到多台机器上).每个进程都会打开一个数据库连接,读取一些数据然后做一些计算.我们用这种方式扩展系统以满足客户的需求,在刚开始的那段时间是很成功的.但是随着时间的推移,我们发现系统利用率增长到某个点之后,就会出现从数据库中读取数据的操作会超时的现象.

我们的DBA仔细研究了日志试图找到出问题的地方.最终,他们发现是由于系统中没有进行任何速率限制,各个进程互相干扰.由于不同进程试图从磁盘上读取不同部分的数据,因此磁盘利用率会飙升到100%且持续居高不下.这导致了一个恶性循环:超时->重试->继续超时->继续重试... 任务永远无法完成.

为了解决这个问题,我们设计了一个系统,该系统对数据库连接数做了限制,并且还限制了每个链接每秒的读取速率进行了限制,然后问题就解决了.客户需要等待更长的时间才能完成任务,但最终任务完成了,我们可以进行正确的容量规划,以便有组织的扩展系统容量.

****

通过设置速率限制,你可以防止系统的性能和稳定性超过你研究过的边界.如果你想扩大这个边界,你可以在经过大量的测试后以可控的方式扩展.

在收费系统的场景下,速率限制可以让你与客户保持一个良好的关系.你可以让用户在严格受限的速率下访问你的系统.Google在其云服务中就采取了这种方法,并获得了巨大成功.

在用户成为付费用户之后,速率限制甚至可以保护用户.由于大多数场景对系统的访问都是有计划的(例如失败后重试),因此很容易产生一个无限制访问付费系统的bug.这可能是个非常昂贵的错误,并使双方都陷入一个尴尬的境地:是服务提供者承担这些成本并免去无意义访问的费用,还是强迫用户支付账单,最终永久破坏双方的关系?

速率限制通常是从资源提供者的角度来考虑的,但对用户而言也是有好处的.假如我刚刚了解如何使用一个API,此时为这个API调用设置一个速率限制对于而言会比较安心,因为我确定这样不会给自己惹麻烦.

希望我已经提供了足够的理由,使你相信即使设置了一个永远不会到达的速率,速率限制依然有用.速率限制很容易创建,且解决了很多问题,很难找到不使用的理由.

在GO语言中如何实现速率限制?

大多数速率限制是通过使用一种称为令牌桶的算法来实现的.它非常易于理解,并且相对容易实现.让我们来看看它背后的原理.

假设为了使用某个资源,你必须拥有该资源的访问令牌.若没有这个令牌,则你的请求会被拒绝.想象这些令牌被存储在一个桶中,等待被取出来使用.这个桶的深度为`d`,表示它最多可以同时容纳`d`个访问令牌.举例来说,如果桶的深度为5,那么它最多可以容纳5个令牌.

现在,每当你需要访问资源时,你都要从桶中取出一个令牌.如果你的桶里有5个令牌,且你访问资源5次,那么你都可以成功访问;但是在第6次尝试时,就没有可用的访问令牌了.你要么将这个请求排队,直到令牌可用;要么拒绝该请求.

下面是一个时间表,用于帮助可视化这个概念.`time`列表示时间间隔(单位:秒);`bucket`列表示桶中剩余访问令牌的数量;`request`列中的`tok`表示成功的请求(后续的时间表中,我们将假设请求是瞬时的,以简化概念).

****

此处我怀疑作者还假定了请求是以1个/s发送的,后续的例子都是

****


|time|bucket|request|comment|
|:-:|:-:|:-:|:-:|
|0|5|tok|请求成功|
|0|4|tok|请求成功|
|0|3|tok|请求成功|
|0|2|tok|请求成功|
|0|1|tok|请求成功|
|0|0||请求失败,因为没有token了|
|1|0||请求失败,因为没有token了|

你可以看到在第1秒之前发出的5个请求都可以正常响应,然后由于没有更多的可用令牌,因此请求被阻塞了.

到目前为止都很容易理解.那么该如何补充令牌呢?在令牌桶算法中,我们定义`r`为令牌添加到桶的速率.它可以是1个/ns,或者1个/s.这就是我们通常理解的速率限制:因为我们必须等到新的令牌可用,所以我们可以将操作的速率限制在这个刷新速率内.

以下示例中,令牌桶深度`d`值为1,添加速率`r`为1个/s:

|time|bucket|request|comment|
|:-:|:-:|:-:|:-:|
|0|1||初态.由于`d`=1,故初态同种就存在1个token|
|0|0|tok|有请求进来,从桶中获取token并执行,请求成功|
|1|0||桶中没有可用token,触发添加机制,在第1秒到第2秒期间的请求会失败(因为添加速率1个/秒)|
|2|1||由于`r`=1,故第2秒有一个新的token被放入了桶|
|2|0|tok|有请求进来,从桶中获取token并执行,请求成功|
|3|0|桶中没有可用token,触发添加机制,在第3秒到第4秒期间的请求会失败(因为添加速率1个/秒|
|4|1|由于`r`=1,故第4秒有一个新的token被放入了桶|
|4|0|tok|有请求进来,从桶中获取token并执行,请求成功|

可以看到,虽然每秒都能发起请求,但请求的执行被限制为每隔1s执行1次.速率限制非常有效!

现在有2个可以调整的设置:可立即使用的令牌数量(桶的深度`d`)和令牌重新填充的速率(`r`).通过这两个设置,我们可以控制突发性请求和请求的总体速率.突发性是指以桶是满的为前提时,可以进行多少次请求.

以下示例中,令牌桶深度`d`值为5,添加速率`r`值为0.5个/s:

|time|bucket|request|comment|
|:-:|:-:|:-:|:-:|
|0|5||初态.`d`=5|
|0|4|tok|第0秒时进来了一个请求,从桶中获取token并执行,请求成功,此时桶中还有4个token|
|0|3|tok|第0秒时进来了一个请求,从桶中获取token并执行,请求成功,此时桶中还有3个token|
|0|2|tok|第0秒时进来了一个请求,从桶中获取token并执行,请求成功,此时桶中还有2个token|
|0|1|tok|第0秒时进来了一个请求,从桶中获取token并执行,请求成功,此时桶中还有1个token|
|0|0|tok|第0秒时进来了一个请求,从桶中获取token并执行,请求成功,此时桶中没有token了,触发添加机制|
|1|0(0.5)||在第1秒时,前0.5秒桶中没有token,后0.5秒桶中有1个token.即:在第1秒到第1.5秒期间的请求会失败.|
|2|1||桶中有1个token|
|2|0|tok|第2秒时进来了一个请求,从桶中获取token并执行,请求成功,此时桶中没有token了,触发添加机制|
|3|0(0.5)||在第3秒时,前0.5秒桶中没有token,后0.5秒桶中有1个token.即:在第3秒到第3.5秒期间的请求会失败.|
|4|1||桶中有1个token|
|4|0|tok|第4秒时进来了一个请求,从桶中获取token并执行,请求成功,此时桶中没有token了,触发添加机制|

本例中,我们能够立刻完成5个请求,在此之后只能每2秒完成1个请求.突发请求集中在开始阶段.

注意,用户可能不会一次性消耗完令牌桶中的所有令牌.令牌桶的深度`d`仅仅控制的是桶的容量.以下示例中,用户先在开始时集中发送了2个请求,过了4秒之后又集中发送了5个请求(桶的深度`d`=5,添加速率`r`=1个/s):

|time|bucket|request|comment|
|:-:|:-:|:-:|:-:|
|0|5||初态.`d`=5|
|0|4||请求成功,此时桶中还有4个令牌|
|0|3||请求成功,此时桶中还有3个令牌|
|1|3||第1秒时由于桶不满,触发添加机制,添加速率为1个/s,因此在第1秒内桶中还是只有3个令牌.且按照题设,此时没有请求进来|
|2|4||第2秒时由于桶不满,继续触发添加机制.但此时由于第1秒就触发了添加机制,因此桶中多了1个令牌,此时桶中有4个令牌.且按照题设,此时没有请求进来|
|3|5||由于第2秒依旧在触发添加机制,因此桶中又多了1个令牌,此时桶中有5个令牌.此时桶满了,不再触发添加机制.且按照题设,此时没有请求进来|
|4|5||桶满了.且按照题设,此时没有请求进来|
|5|4|tok|请求成功,此时桶中还有4个令牌|
|5|3|tok|请求成功,此时桶中还有3个令牌|
|5|2|tok|请求成功,此时桶中还有2个令牌|
|5|1|tok|请求成功,此时桶中还有1个令牌|
|5|0|tok|请求成功,此时桶中没有令牌了|

当用户有可用的令牌时,突发性允许用户以其能力范围为上限来访问系统.对于那些只是间断性的访问系统,却希望在访问期间能尽快完成的用户来说,突发性很实用.你只需要确保你的系统能够同时处理所有用户的突发请求,或者确保不会有足够多的用户同时突发请求进而影响你的系统.无论哪种方式,速率限制都可以让你让你有计划地对风险进行控制.

让我们来实现一下这个算法,看看在GO语言中加入令牌桶算法时会存在哪些问题.

假设我们可以访问一个API,并提供了一个GO实现的客户端用于访问这个API.这个API有2个接口:一个用于读取文件,另一个用于将域名解析为IP地址.为了简单起见,例子中将省略入参和返回值.以下为客户端代码:

```go
package main

import "context"

func main() {

}

type APIConnection struct{}

func (a *APIConnection) ReadFile(ctx context.Context) error {
	// 此处假装在调用读取文件的API
	return nil
}

func (a *APIConnection) ResolveAddress(ctx context.Context) error {
	// 此处假装在调用解析地址为IP的API
	return nil
}

func Open() *APIConnection {
	return &APIConnection{}
}
```

因为理论上来讲这个请求应该是通过网络传输的,因此将`context.Context`作为第1个参数,以便当需要取消请求时或需要将一些值传给服务端时使用.这是相当标准的做法.

我们将创建一个简单的驱动程序来访问这些API.这个程序需要读取10个文件并解析10个地址,但这些文件和地址之间彼此没有关联,因此这个程序可以并发调用.在之后的例子中,浙江有助于对APIClient进行压测并添加速率限制.

目录结构如下:

```
17-callAPIClientNoRateLimit % tree ./
./
├── callAPIClientNoRateLimit.go
└── client
    └── client.go

1 directory, 2 files
```

其中`client/client.go`的代码即为上述的客户端代码.`callAPIClientNoRateLimit.go`代码如下:

```go
package main

import (
	"code/chapter5/17-callAPIClientNoRateLimit/client"
	"context"
	"log"
	"os"
	"sync"
)

func main() {
	defer log.Printf("Done.\n")

	log.SetOutput(os.Stdout)
	log.SetFlags(log.Ltime | log.LUTC)

	apiConnection := client.Open()

	var wg sync.WaitGroup
	wg.Add(20)

	for i := 0; i < 10; i++ {
		go func() {
			defer wg.Done()

			err := apiConnection.ReadFile(context.Background())
			if err != nil {
				log.Printf("cannot read file: %v\n", err)
			}

			log.Printf("ReadFile\n")
		}()
	}

	for i := 0; i < 10; i++ {
		go func() {
			defer wg.Done()

			err := apiConnection.ResolveAddress(context.Background())
			if err != nil {
				log.Printf("cannot resolve address: %v\n", err)
			}

			log.Printf("ResolveAddress\n")
		}()
	}

	wg.Wait()
}
```

运行结果如下:

```
go run callAPIClientNoRateLimit.go 
10:51:09 ReadFile
10:51:09 ReadFile
10:51:09 ReadFile
10:51:09 ReadFile
10:51:09 ReadFile
10:51:09 ReadFile
10:51:09 ReadFile
10:51:09 ResolveAddress
10:51:09 ReadFile
10:51:09 ResolveAddress
10:51:09 ResolveAddress
10:51:09 ResolveAddress
10:51:09 ResolveAddress
10:51:09 ReadFile
10:51:09 ResolveAddress
10:51:09 ResolveAddress
10:51:09 ResolveAddress
10:51:09 ResolveAddress
10:51:09 ResolveAddress
10:51:09 ReadFile
10:51:09 Done.
```

可以看到所有的API请求几乎都是同时处理的.因为我们没有设置速率限制,因此我们的客户端可以以任意频率访问系统.现在要告诉你的是:你的程序中存在一个导致无限循环的错误.如果没有速率限制,我可能会面临一张可怕的账单.

现在让我们引入速率限制器.我将在`APIConnection`中设置速率限制,但通常速率限制是设置在服务端的,这样用户就无法绕过它了.生产环境中,客户端也会有限速,以免客户端发起不必要的调用,但这只是一种优化手段.对于我们的目的而言,仅在客户端加一个速率限制器会使得整个例子保持简单.

此处使用[`golang.org/x/time/rate`](https://pkg.go.dev/golang.org/x/time/rate)包中的令牌桶速率限制器来进行演示.之所以选择这个包是因为它和标准库非常接近.当然,还有一些其他的包也可以实现相同功能,且可以用于生产环境.但对于我们现在而言,`golang.org/x/time/rate`这个包很简单,且也足够现在使用了.

我们和这个包交互的第1种方式是通过`Limit`类型和`NewLimiter()`函数,其定义如下:

```go
// Limit 定义了事件的最大频率
// Limit 表示每秒允许的最大事件数量
// Limit 为0表示不允许任何事件发生
type Limit float64
```

```go
// NewLimiter 返回一个新的 Limiter 实例.该实例允许
// 事件发生的速率为r,并允许最多b个令牌同时爆发
func NewLimiter(r Limit, b int) *Limiter {
	return &Limiter{
		limit: r,
		burst: b,
	}
}
```

在`NewLimiter()`函数中,我们看到了2个熟悉的参数:`r`和`b`.`r`即为之前提到过的向桶中添加token的速率,而`b`则表示桶的深度.

`rates`包还定义了一个辅助函数`Every()`,用于将`time.Duration`转换为`Limit`:

```go
// Every 将事件之间的最小时间间隔转换为 Limit (每秒允许的最大事件数量)
func Every(interval time.Duration) Limit {
	if interval <= 0 {
		return Inf
	}
	return 1 / Limit(interval.Seconds())
}
```

`Every()`函数是有意义的,但我想要的速率限制是每个时间段内允许的操作数量,而非是每个请求之间的最小间隔.可以将其表达如下:

```go
rate.Limit(events/timePeriod.Seconds())
```

****

个人理解:

- `events`:事件的数量
- `timePeriod.Seconds()`:以秒表达的给定的时间段
- 即:`事件数量/时长 = 每秒允许的最大事件数量`

****

可是我不想每次都写一次这个代码,并且由于`Every()`函数有一些特殊的逻辑(若给定的时间间隔小于等于0,则返回一个`rate.Inf`表示对事件的频率没有限制).因此,我们基于`Every()`函数来封装我们的辅助函数:

```go
// Per 返回一个 rate.Limit 实例.该实例代表在给定的时段duration内有给定数量eventCount个事件发生的前提下
// 每秒允许的最大事件数量
func Per(eventCount int, duration time.Duration) rate.Limit {
	return rate.Every(duration / time.Duration(eventCount))
}
```

在创建了`rate.Limiter`之后,我们需要使用它来阻塞请求,直到获取到访问令牌为止.使用`Wait()`方法可以实现这个功能,它只是调用`WaitN()`方法,参数值为1.

```go
// Wait 是 WaitN(ctx, 1) 的简写.
func (lim *Limiter) Wait(ctx context.Context) (err error) {
	return lim.WaitN(ctx, 1)
}
```

```go
// WaitN 会阻塞,直到 Limiter 实例允许 n 个事件发生
// 若 n 超过 Limiter 的 burst 大小,或预计的等待时间超过上下文的截止时间,则上下文会被取消.
// 若速率限制为 Inf,则忽略 burst的限制.
func (lim *Limiter) WaitN(ctx context.Context, n int) (err error) {
	// 测试代码使用虚拟计时器生成器调用 lim.wait
	// 这里是真实的计时器生成器
	newTimer := func(d time.Duration) (<-chan time.Time, func() bool, func()) {
		timer := time.NewTimer(d)
		return timer.C, timer.Stop, func() {}
	}

	return lim.wait(ctx, n, time.Now(), newTimer)
}
```

现在已经集齐了对API进行速率限制的所有要素,修改`APIConnection`类型并尝试:

目录结构如下:

```
tree ./
./
├── client
│   └── client.go
└── simpleRateLimit.go

1 directory, 2 files
```

`client/client.go`:

```go
package client

import (
	"context"
	"golang.org/x/time/rate"
)

type APIConnection struct {
	rateLimiter *rate.Limiter
}

func (a *APIConnection) ReadFile(ctx context.Context) error {
	if err := a.rateLimiter.Wait(ctx); err != nil {
		return err
	}

	// 此处假装在调用读取文件的API
	return nil
}

func (a *APIConnection) ResolveAddress(ctx context.Context) error {
	if err := a.rateLimiter.Wait(ctx); err != nil {
		return err
	}
	
	// 此处假装在调用解析地址为IP的API
	return nil
}

func Open() *APIConnection {
	return &APIConnection{
		rateLimiter: rate.NewLimiter(rate.Limit(1), 1),
	}
}
```

- 第32行:`rateLimiter: rate.NewLimiter(rate.Limit(1), 1)`.此处设定调用API的速率为1次/秒
- 第13行和第22行:`if err := a.rateLimiter.Wait(ctx); err != nil`.此处等待速率限制器有足够的令牌来完成请求

`simpleRateLimit.go`:

```go
package main

import (
	"code/chapter5/19-simpleRateLimit/client"
	"context"
	"log"
	"os"
	"sync"
)

func main() {
	defer log.Printf("Done.\n")

	log.SetOutput(os.Stdout)
	log.SetFlags(log.Ltime | log.LUTC)

	apiConnection := client.Open()

	var wg sync.WaitGroup
	wg.Add(20)

	for i := 0; i < 10; i++ {
		go func() {
			defer wg.Done()

			err := apiConnection.ReadFile(context.Background())
			if err != nil {
				log.Printf("cannot read file: %v\n", err)
			}

			log.Printf("ReadFile\n")
		}()
	}

	for i := 0; i < 10; i++ {
		go func() {
			defer wg.Done()

			err := apiConnection.ResolveAddress(context.Background())
			if err != nil {
				log.Printf("cannot resolve address: %v\n", err)
			}

			log.Printf("ResolveAddress\n")
		}()
	}

	wg.Wait()
}
```

运行结果:

```
go run simpleRateLimit.go 
17:44:53 ReadFile
17:44:54 ResolveAddress
17:44:55 ReadFile
17:44:56 ReadFile
17:44:57 ReadFile
17:44:58 ReadFile
17:44:59 ResolveAddress
17:45:00 ReadFile
17:45:01 ReadFile
17:45:02 ReadFile
17:45:03 ResolveAddress
17:45:04 ResolveAddress
17:45:05 ResolveAddress
17:45:06 ResolveAddress
17:45:07 ResolveAddress
17:45:08 ResolveAddress
17:45:09 ResolveAddress
17:45:10 ResolveAddress
17:45:11 ReadFile
17:45:12 ReadFile
17:45:12 Done.
```

可以看到,相比前一个例子的那种"所有请求同时被发送",现在每秒只能完成1个请求.看起来速率限制器已经生效了!

这就有了一个基本的限速.但是在生产中,我们可能需要更复杂的设置.我们可能希望建立多个层级的限速器:细粒度的限速器用于限制每秒的请求数,粗粒度的限速器用于限制每分钟、每小时或每天的请求数.

在某些情况下,可以使用单个限速器来实现.但是,并非所有情况都能这样做,且将所有的时间单位的限速器放在同一个层级上,会丢失很多关于限速器意图的信息.因此,我发现将不同时间粒度的限速器保持独立,并将它们组合成一个限速器,该限速器用于管理调用,这样的代码组织更清晰.为此我创建了一个聚合速率限制器,名为`multiLimiter`,代码如下:

目录结构如下:

```
tree ./
./
├── multiLimiter
│   └── multiLimiter.go
└── multiLimiterI
    └── multiLimiterI.go

2 directories, 2 files
```

其中`multiLimiterI/multiLimiterI.go`为接口定义:

```go
package multiLimiterI

import (
	"context"
	"golang.org/x/time/rate"
)

type RateLimiter interface {
	Wait(ctx context.Context) error
	Limit() rate.Limit
}
```

- 第8行:`type RateLimiter interface`.此处定义了`RateLimiter`接口,以便其实现`MultiLimiter`可以递归地定义其他`MultiLimiter`实例

`multiLimiter/multiLimiter.go`为其实现:

```go
package multiLimiter

import (
	"code/chapter5/20-multiLimiter/multiLimiterI"
	"context"
	"golang.org/x/time/rate"
	"sort"
)

type MultiLimiter struct {
	limiters []multiLimiterI.RateLimiter
}

func (m *MultiLimiter) Wait(ctx context.Context) error {
	for _, limiter := range m.limiters {
		if err := limiter.Wait(ctx); err != nil {
			return err
		}
	}

	return nil
}

func (m *MultiLimiter) Limit() rate.Limit {
	return m.limiters[0].Limit()
}

func NewMultiLimiter(limiters ...multiLimiterI.RateLimiter) *MultiLimiter {
	byLimit := func(i, j int) bool {
		// 按限流器限制的速度从小到大排序
		return limiters[i].Limit() < limiters[j].Limit()
	}

	sort.Slice(limiters, byLimit)
	return &MultiLimiter{limiters: limiters}
}
```

- 第34行:`sort.Slice(limiters, byLimit)`.此处做了一个优化,将`MultiLimiter`中所有`MultiLimiter`按速度从小到大排序
- 第25行:`return m.limiters[0].Limit()`.因为在实例化`MultiLimiter`时,对子`RateLimiter`实例进行了排序,因此可以简单返回最严格的限制(要求速率最低的那个限速器),即切片中的第1个元素.

`Wait()`方法遍历所有子限速器,并对每个限速器调用其`Wait()`方法.这些调用可能会阻塞,也可能不阻塞,但我们需要通知每个限速器进行请求,以便可以减少令牌桶中的令牌数量.通过等待每个限速器,我们确保阻塞的时间恰好为最长等待时间.这是因为如果我们执行时间较短的等待,那么当下一次碰到时间较长的等待时,则最长时间的等待将会重新计算为剩余时间.这是因为当较早的等待(时间较短的等待)阻塞时,后面的等待(时间较长的等待)正在重新填充它们的令牌桶,导致所有请求在第1次阻塞后都会立即返回.

****

注:此处作者的含义是:**如果没有排序,则在先等速度较快的限流器,再等速度较慢的限流器的场景下,则在通过了速度较快的限流器限制后,需要继续等待的时间为速度较慢的限流器的剩余时间.因为在等待速度较快的限流器时,速度较慢的限流器同时也在计算向它的令牌桶中添加令牌的时间**.

但如果速度较慢的限流器的桶较大,速度较快的限流器的桶较小,则还是需要等待.作者这段话里,没有考虑桶大小的问题,更多的是基于他后续给的例子讲的.

作者并不是想表达如果不排序则最终的等待时长有误的含义!

****

现在我们有了可以进行多重限速的限速方法,借此机会对`APIConnection`增加一些细节.重新定义`APIConnection`,同时设置每秒和每分钟的限制:

```
tree ./
./
├── client
│   └── client.go
├── multiLimiter
│   └── multiLimiter.go
└── multiLimiterI
    └── multiLimiterI.go

3 directories, 3 files
```

其中`client/client.go`为定义`APIConnection`的代码:

```go
package client

import (
	"code/chapter5/20-multiLimiter/multiLimiter"
	"code/chapter5/20-multiLimiter/multiLimiterI"
	"context"
	"golang.org/x/time/rate"
	"time"
)

type APIConnection struct {
	rateLimiter multiLimiterI.RateLimiter
}

func (a *APIConnection) ReadFile(ctx context.Context) error {
	if err := a.rateLimiter.Wait(ctx); err != nil {
		return err
	}

	// 此处假装在调用读取文件的API
	return nil
}

func (a *APIConnection) ResolveAddress(ctx context.Context) error {
	if err := a.rateLimiter.Wait(ctx); err != nil {
		return err
	}

	// 此处假装在调用解析地址为IP的API
	return nil
}

func Open() *APIConnection {
	// 秒级限速器 限制每秒最多2个事件 桶深度为1
	secondLimit := rate.NewLimiter(Per(2, time.Second), 1)

	// 分级限速器 限制每分钟最多10个事件 桶深度为10
	minuteLimit := rate.NewLimiter(Per(10, time.Minute), 1)

	return &APIConnection{
		rateLimiter: multiLimiter.NewMultiLimiter(secondLimit, minuteLimit),
	}
}

func Per(eventCount int, duration time.Duration) rate.Limit {
	return rate.Every(duration / time.Duration(eventCount))
}
```

- 第35行:`secondLimit := rate.NewLimiter(Per(2, time.Second), 1)`.此处定义了每秒的请求数量限制,以应对突发请求
- 第38行:`minuteLimit := rate.NewLimiter(Per(10, time.Minute), 1)`.此处定义了每分钟的请求数量限制,桶深为10,以便为用户提供初始的令牌池.每秒的请求数量限制将确保我们不会因突发过多请求而导致系统过载
- 第41行:`rateLimiter: multiLimiter.NewMultiLimiter(secondLimit, minuteLimit),`.此处将这2个限速器合并成1个,并作为`APIConnection`的主限速器

对`APIConnection`调用的代码不变.

运行结果:

```
go run multiLimiter.go
15:02:33 ReadFile 		 #1
15:02:34 ResolveAddress #2
15:02:34 ReadFile 		 #3
15:02:35 ResolveAddress #4
15:02:35 ResolveAddress #5
15:02:36 ResolveAddress #6
15:02:36 ResolveAddress #7
15:02:37 ResolveAddress #8
15:02:37 ReadFile		 #9
15:02:38 ResolveAddress #10
15:02:39 ReadFile		 #11
15:02:45 ReadFile		 #12
15:02:51 ReadFile		 #13
15:02:57 ReadFile		 #14
15:03:03 ReadFile		 #15
15:03:09 ResolveAddress	 #16
15:03:15 ReadFile		 #17
15:03:21 ReadFile		 #18
15:03:27 ResolveAddress #19
15:03:33 ResolveAddress #20
15:03:33 Done.
```

注:`#序号`是我自己手动加的,为了方便后边解释.

从日志中可以看到,现在每秒可以发送2个请求.直到第11个请求开始,每隔6秒发出1个请求.这是因为到第11个请求时,耗尽了`minuteLimit`的令牌桶,因此开始受到限制.

第11个请求在第10个请求之后1秒就发出了,而非是6秒.这可能有点反直觉.这是因为虽然限制了请求为10个/分钟,但这里"分钟"的概念是一个滑动窗口.当到达第11个请求时,时间从`15:02:33`到`15:02:39`,`minuteLimit`正好又生成了一个令牌.

以这种方式定义限流器,可以清晰地表达粗粒度的限制,且同时仍然可以在细粒度的层面上做精细化的控制.

这种技术还允许我们考虑除时间外的其他维度.当对系统进行限流时,可能会限制多个维度.你可能对API的请求数量有限制,同时也可能对其他资源(例如磁盘访问、网络访问等)有限制.稍微扩展以上例子,增加磁盘和网络访问控制:

目录结构如下:

```
tree ./
./
├── client
│   └── client.go
├── multiLimiter
│   └── multiLimiter.go
├── multiLimiterI
│   └── multiLimiterI.go
└── tieredMultiLimiter.go

3 directories, 4 files
```

其中只有`client/client.go`中的代码和上文不同:

```go
package client

import (
	"code/chapter5/21-tieredMultiLimiter/multiLimiter"
	"code/chapter5/21-tieredMultiLimiter/multiLimiterI"
	"context"
	"golang.org/x/time/rate"
	"time"
)

type APIConnection struct {
	networkLimit multiLimiterI.RateLimiter
	diskLimit    multiLimiterI.RateLimiter
	apiLimit     multiLimiterI.RateLimiter
}

// ReadFile 模拟读取文件 前10个请求每秒1个 从第11个开始每6秒1个 第11个请求会在第10个请求等待2s后执行
func (a *APIConnection) ReadFile(ctx context.Context) error {
	err := multiLimiter.NewMultiLimiter(a.apiLimit, a.diskLimit).Wait(ctx)
	if err != nil {
		return err
	}

	// 此处假装在调用读取文件的API
	return nil
}

// ResolveAddress 模拟解析地址为IP 前10个请求每秒2个 从第11个开始每3秒1个 第11个请求会在第10个请求等待1s后执行
func (a *APIConnection) ResolveAddress(ctx context.Context) error {
	err := multiLimiter.NewMultiLimiter(a.apiLimit, a.networkLimit).Wait(ctx)
	if err != nil {
		return err
	}

	// 此处假装在调用解析地址为IP的API
	return nil
}

func Open() *APIConnection {
	return &APIConnection{
		apiLimit: multiLimiter.NewMultiLimiter(
			// API限速器1: 限制每秒最多2次访问 桶深为2
			rate.NewLimiter(Per(2, time.Second), 2),
			// API限速器2: 限制每分钟最多10次访问 桶深为10
			rate.NewLimiter(Per(10, time.Minute), 10),
		),
		diskLimit: multiLimiter.NewMultiLimiter(
			// 磁盘访问限速器1: 限制每秒最多1次访问 桶深为1
			rate.NewLimiter(rate.Limit(1), 1),
		),
		networkLimit: multiLimiter.NewMultiLimiter(
			// 网络访问限速器1: 限制每秒最多3次访问 桶深为3
			rate.NewLimiter(Per(3, time.Second), 3),
		),
	}
}

func Per(eventCount int, duration time.Duration) rate.Limit {
	return rate.Every(duration / time.Duration(eventCount))
}
```

- 第41行:`apiLimit: multiLimiter.NewMultiLimiter`.此处为API调用设置了限流器,该限流器限制每分钟最多发送10个请求且每秒最多发送2个请求
- 第47行:`diskLimit: multiLimiter.NewMultiLimiter`.此处为磁盘读取设置了限流器,该限流器限制每秒最多读取1次
- 第51行:`networkLimit: multiLimiter.NewMultiLimiter`.此处为网络访问设置了限流器,该限流器限制每秒最多访问3次
- 第19行:`err := multiLimiter.NewMultiLimiter(a.apiLimit, a.diskLimit).Wait(ctx)`.当需要读取文件时,将API限流器和磁盘限流器进行组合.其效果为:在API限流器中的分钟限流器的令牌桶中还有令牌的前提下,`ReadFile()`最终受磁盘限流器控制,最多每秒执行1次
- 第30行:`err := multiLimiter.NewMultiLimiter(a.apiLimit, a.networkLimit).Wait(ctx)`.当需要网络访问时,将API限流器和网络访问限流器进行组合.其效果为:在API限流器中的分钟限流器的令牌桶中还有令牌的前提下,`ResolveAddress`最终受API限流器中的秒级限流器控制,最多每秒执行2次

运行结果:

```
go run tieredMultiLimiter.go 
16:02:24 ResolveAddress
16:02:24 ResolveAddress
16:02:25 ReadFile
16:02:25 ResolveAddress
16:02:26 ReadFile
16:02:26 ResolveAddress
16:02:27 ResolveAddress
16:02:27 ResolveAddress
16:02:28 ResolveAddress
16:02:28 ResolveAddress
16:02:30 ReadFile
16:02:36 ReadFile
16:02:42 ReadFile
16:02:48 ReadFile
16:02:54 ReadFile
16:03:00 ResolveAddress
16:03:06 ReadFile
16:03:12 ReadFile
16:03:18 ReadFile
16:03:24 ResolveAddress
16:03:24 Done.
```

可以看到,`ResolveAddress`最多每秒可以执行2次;而`ReadFile`最多每秒只能执行1次

我可以在这里画一个时间表来解释每个调用发生在哪里,但这样会让我们忽略重点.相反,把重点放在以下事件上:我们能够将限速器组合成对每个调用都有意义的限速组,针对每个调用进行限流,且`APIConnection`也有着正确的行为.如果我们观察它是如何工作的,我们会注意到`ResolveAddress`的调用似乎更规律了,且大部分对`ResolveAddress`的调用在前2/3的调用(总共20次调用,也就是在前16次)中完成了.这可能与goroutine的调度有关,但更有可能的是因为限流器在起作用!

另外,`rate.Limiter`还有一些其他的特殊技巧来进行优化或处理其他用例.本小节仅讨论了它等待令牌桶接收令牌的能力,但如果你只是想用它,只需要知道它还有一些其他功能即可.

在本届中,我们讨论了使用速率限制的理由、构建了限流器、了解了GO中令牌桶算法的实现以及如何将限制器组合以成为一个更大、更复杂的限流器.这应该为你提供了有关速率限制的良好描述,并帮助你开始在实际应用中使用它们.