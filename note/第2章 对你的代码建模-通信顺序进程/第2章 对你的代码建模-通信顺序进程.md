# Concurrency In Go

## 第2章 对你的代码建模:通信顺序进程

### 并发与并行的区别

这两种模式总是被混用来表达"某种和其他事物同时运行的事物".

**并发属于代码;并行属于一个运行中的程序**

****

个人理解:

并发是描述代码的一个属性,表示有2段代码可以被同时运行,但不代表这两段代码一定会被同时运行,比如这两段代码运行在了只有1核CPU的机器上;

并行描述的是多个程序运行时的状态,表示在某台机器上有多个程序正在同时被运行;

****

假设我故意写了2部分可以并行运行的程序,我可以保证在程序实际运行的时候并行执行吗?我在只有1个核心的机器上运行会发生什么?

代码块可能表现的像是在并发的执行,但实际上,它们在用不可被辨别的速度进行顺序执行.CPU的上下文在1个时间颗粒度之内一直在不同的程序之间进行切换分享CPU时间使得任务好像是在并行执行.如果在有2个CPU核心的机器上执行相同的二进制文件,代码块可能真的是在并行执行.

****

个人理解:

原文:CPU的上下文在1个时间颗粒度之内一直在不同的程序之间进行切换分享CPU时间使得任务好像是在并行执行.

CPU上下文:即CPU寄存器和程序计数器.它们是CPU在运行任何任务前,必须的依赖环境.

- CPU寄存器时CPU内置的容量小、但速度极快的内存
- 程序计数器是用来存储CPU正在执行的指令位置或即将执行的下一条指令的位置

CPU上下文切换:先把前一个任务的CPU上下文(即CPU寄存器和程序计数器)保存起来,然后加载新任务的上下文到这些寄存器和程序计数器中,最后再跳转到程序计数器所指的新位置,运行新任务.而原来被保存起来的上下文,会存储在系统内核中,并在任务重新调度执行时再次加载进来.这样就能保证任务原来的状态不受影响,让任务看起来还是连续运行.

1个时间颗粒度:个人认为是CPU管理时间的最基本单位.我自己认为这就是1次晶振时间.但是从计算机科学的角度上来讲,只有1个核的CPU1次晶振能否做多次运算这个是我不知道的.但我认为不妨碍我对这句话的整体理解.

![原文解读_CPU的上下文切换](../img/chapter2/原文解读_CPU的上下文切换.jpg)

****

这揭示了一些很重要的事情:

1. 我们并没有编写并行的代码,只有我们希望可以并行执行的并发代码.
	
	****
	
	个人理解:
	
	原文:我们并没有编写并行的代码
	
	2个程序中可能都没有并发的代码.比如程序A循环打印5次"Hello",程序B循环打印5次"World".
	
	原文:只有我们希望可以并行执行的并发代码
	
	但这2个程序可以同时一起被执行.当这2个程序同时一起被执行时,这2个程序本身是并行执行的;这2个程序的代码也就成为了并发代码.
	
	****
	
2. 并行是程序运行时的属性,而不是我们的代码
3. 可能我们对我们所写的并发代码是否并行执行,保持不知情
	
	是否真的并行执行,只有在程序模型之下的抽象层实现:并发原语、程序的运行时、操作系统、操作系统所运行的平台(容器、虚拟机、物理机)以及CPU.这些抽象给予我们区分并发和并行的能力

4. 并行是一个时间或者上下文的函数.这里,上下文定义为2个或以上的操作被认为是并行的界限

	****
	
	个人理解:

	在第1章我们讲原子性的时候,上下文也被定义成了一个界限.在这个界限之内,操作是原子的;在这个界限之外,操作可能不是原子的.
	
	同样的,此处上下文也是一个界限,一个用于界定是否并行的界限.2个或以上的操作可以同时进行,则这多个操作是并行的;2个或以上的操作不能同时进行,则这多个操作不是并行的.
	
	****

例:若定义上下文为一段5s的时长,此时执行了2个分别消耗1s的操作,则认为这些操作是并行执行的;若定义上下文为一段1s的时长,则2个操作各需1个上下文的时长,则我们应该认为操作是分别运行的.

但是要记住:**上下文和时间并没有关系**.

举个实际的例子.**假设我们讨论的上下文是你的计算机**.那么合理地认为,在我的计算机上执行一个进程,不会影响到你的计算机上执行的一个进程.如果我们都开启一个计算器进程来做运算,那么我所操作的计算器不应该影响你所操作的计算器.

我们来拆分这个例子,可以得到所有的片段:

- 上下文:我们各自的计算机
- 并发操作:你和我在各自计算机上的计算器进程做运算

在这个过程中,我们选择用独立的计算机、操作系统和进程来考虑问题,从而对井发操作进行建模.**这些抽象概念让我们自信地断言正确性**.

一台计算机上的一个进程不被其他计算机上的进程影响,这是理所当然的.但是如果是一台计算机上的两个进程,它们互相之间是有可能产生影响的.

但是如果我们从进程的视角看待问题,或许会简单一些.回到计算器的例子,我们也可以认为2个用户在同1台机器上运行的2个计算器的进程,彼此之间是独立的.**这是进程的边界线和操作系统帮助我们按照一个符合逻辑的方式来思考问题**.

如果我们再向下移动到操作系统线程的边界,我们第1章探讨的问题就都开始出现了:条件竞争、死锁、活锁以及饥饿.如果我们有一个所有计算机上的用户都可见的计算器进程,就会使并发逻辑变的很难正确.

当我们的视角逐渐移动到这个抽象层的下方(OS -> 进程 -> 线程)时,对事物的建模变的越来越难以理解,而抽象对于我们来讲也越来越重要.换言之,**编写正确的并发逻辑越难,越需要我们将很简单的并发原语组合起来使用.但行业中的大多数并发逻辑都是写在最高抽象层次之一的系统线程上的**.

在GO出现之前,这是大多数编程语言的抽象链的最终解决方案.如果要写并发代码,就需要用线程来建模,并同步它们之间的内存访问.如果有很多事物需要建模,而你的计算机又不能处理那么多线程,则需要创建一个线程池,并将你的操作复用到线程池中.

GO在这个链条中加入了一个新元素:goroutine.并引入了新的原语:channel.而且它们使并发变的简单化.

**当然,线程依旧存在,但是我们几乎不在操作系统的线程层面考虑问题了.取而代之的是,我们对于事物站在goroutine和channel的角度来思考,偶尔站在共享内存的角度来思考**.

### 什么是CSP

CSP:是一篇论文的名字.Communicating Sequential Processes.通信顺序进程.表示一种"在进程间正确通信"的方法.

在这篇论文中,作者认为输入和输出是两个被忽略的编程原语,尤其时在并发代码中.

为了支持他的观点(输入与输出需要被按照语言的原语来考虑),作者的CSP程序设计语言包含了用来建模输入与输出,或者说"在进程间正确通信"的原语.作者用进程这个术语,来描述所有封装了逻辑的逻辑片段.而这些逻辑片段需要输入才能运行,且这些逻辑片段运行之后的输出,会被其他逻辑片段消费.或许作者使用"函数"这个词来描述更为合适.

为了在进程间通信,作者创造了输入与输出的命令:

- !:发送输入到一个进程(即:给一个进程发送输入)
- ?:读取一个进程的输出

每个命令都必须指定一个输出变量(即:?后边是一个变量,该变量用于接收读取的内容)或目标(即:!前是一个进程,该进程用于接收发送的内容).有时这2个过程会引用相同的东西(即:命令前后都是进程),这种情况下,这两个过程被认为是相对应的.换言之,一个进程的输出应该直接流向另一个进程的输入.下表给出一些示例:

|操作|解释|
|:--:|:--:|
|`cardReader ? cardImage`|从`cardReader`中读取1条记录,并将这个值分配给变量`cardImage`|
|`linePrinter ! lineImage`|向`linePrinter`发送`lineImage`的值|
|`X ? (x, y)`|从名为`X`的进程中输入一对值,并将它们分配给`x`和`y`(个人理解:把进程`X`的输出分配给`x`和`y`)|
|`DIV ! (3 * a + b, 13)`|处理DIV,输出2个指定的值(个人理解:把`3 * a + b`和`13`发送给DIV)|
|`*[c : character; west ? c -> east ! c`]|读取`west`输出的字符,然后发送给`east`.当过程`west`结束时,终止(个人理解:终止的是向`c`的写入)|

这些例子和GO语言的channel很相似.注意最后一个例子,`west`的输出被送到变量c中,然后`east`的输入也是从同一个变量中接收的.这两个过程是相对应的.在作者关于CSP的第1篇论文中,进程只能通过指定来源和目的地进行通信.作者承认这会让代码像一个函数库一样被嵌入到逻辑中,因为代码的使用者必须知道输入和输出的名称.作者当时提出了将输入输出的名字注册成他称之为叫"端口名"的可能性.这个名称在并行命令的头部声明,也就是我们大概可以认为是命名的参数与命名的返回值.

****

个人理解:

以`*[c : character; west ? c -> east ! c]`为例.我想要使用`west`这个过程的输出:

- 首先我要知道的是`west`把它的输出,输出到哪个变量中去了
- 其次我要知道`west`读取哪几个变量才能工作

而这些变量的名字,包括`west`这个过程的名字,我都要知道,才能使用`west`

****

这种语言同时利用了守护命令.一个有守护的命令仅仅是带有左和右倾向的语句,由`→`来分割.左侧的服务是有运行条件的,或者左侧是为了守护右侧服务.

若:

- 左侧运行失败
- 左侧在一个命令执行后,返回false
- 左侧在一个命令执行后退出

则:右侧服务永远不会被执行.

将这些与I/O命令组合起来,就实现了channel.

### 如何帮助你

通常来讲,一种语言会将它们的抽象链结束在系统线程和内存访问同步的层级.GO语言使用goroutine和channel来代替这些概念.

可以将goroutine类比成线程;把一个channel类比成一个mutex.

goroutine把我们从一种必须按照并行的思考方式中解放出来,取而代之的是让我们对问题进行建模,使思考过程更接近自然.

举个例子,我要构建一个Web服务器,在一个仅能够提供线程抽象的语言中,我要思考以下的问题:

- 我的语言是否原生支持线程,还是我要选择一个类库?
- 我的线程限制边界是什么?
- 线程在操作系统中有多重?
- 运行我的程序的各个操作系统,处理这些线程的时候有什么不同?
- 我需要创建一个线程池,来限制我创建的线程数量.我该如何找到最佳的线程池大小?

**而所有这些要考虑的重要问题,都没有直接关系到你要解决的问题.你马上被拉到了如何解决并行问题的技术细节上.**

如果后退一步,开始思考原始问题,那么可以作出如下陈述:独立的用户连接到我的服务端,并开启一个会话.会话为他们的请求提供一个响应.

在GO语言中,我们可以立刻把这个问题用代码表示:我们为每个接入的连接创建1个goroutine,在goroutine中处理请求(可能需要与其他goroutine或数据、服务进行交互),然后从goroutine的函数体中返回.**我们对问题的思考自然地直接映射为如何使用GO语言进行编码**.

我们之所以可以先不用考虑关于并行的问题,是因为goroutine是轻量级的,我们通常不用考虑关于创建新的goroutine所带来的代价而担心.过早的考虑这些,只是完全的过早优化.把这个和线程对比一下,你会发现提前考虑这些事情很明智.(TODO:最后一句话不懂啥意思)

但这并不表示对并发问题的建模不重要.GO围绕并发而设计,GO与它提供的并发原语是一致的.因此会有更少的阻力和更少的bug.

对问题更直观,更自然的映射,有着巨大的好处的同时,它带来了一些有益的副作用.GO的运行时自动将goroutine映射到了系统的线程上,并为我们管理这些goroutine的调度.**这就意味着对于运行时的优化,可以在不改动我们如何模拟问题的前提条件下进行.这是经典的关注点分离**.

并发与并行的解耦还有一个好处:**由GO的运行时为你管理goroutine映射到线程的调度**.GO的运行时可以在goroutine阻塞,等待I/O之类的情况下进行检查,从而把OS的线程重新分配给没有阻塞的goroutine.这也提高了你的代码性能.

现实问题与GO语言代码之间的自然映射带来的另一个好处:**增大了以并发方式建模的问题数量**.我们作为开发人员所面临的问题在现实生活中是并发的,所以我们经常会自然而然的按并发的方式去处理.相比于其他语言,使用GO可以在更细的粒度级别编写并发代码.回到网络服务器的例子上,使用GO处理用户请求时,每个连接有一个独立的goroutine,而不是将连接绑定到一个线程池.更精细的粒度级别使程序可以在运行到主机能够承载的并行数量时,能够动态缩放.这是[Amdahl法则](https://zh.wikipedia.org/wiki/%E9%98%BF%E5%A7%86%E8%BE%BE%E5%B0%94%E5%AE%9A%E5%BE%8B)的实践.(个人理解:可以动态调整Wp的数值,当达到主机能够承载的并行数量时,将Wp缩小)

**channel可以和其他channel进行组合**.这使得编写大规模系统变得简单.可以通过组合输出来协调多个子系统的输入.可以将输入的channel和超时、取消或消息组合到其他的子系统.

**select是GO语言中对channel的一个补充,select使多个通道组合的所有难点得以实现**.select语句使你高效的等待时间,以一种统一的随机方式从竞争的channel中均匀、随机地选择一个消息,并在没有消息的时候继续等待.

### GO语言的并发哲学

GO语言能够让开发者在CSP原语和内存访问同步之间选择.但这可能有点混乱.GO语言的新手经常会有这样的印象:CSP样式编写并发代码是GO语言编写并发代码的唯一方式.在`sync`包的文档中,有如下描述:

`sync`包提供了基本的同步原语,如互斥锁.除了`Once`和`WaitGroup`类型,大部分类型都是供底层库例程使用的.使用channel通信可以更好地完成更高级别的信息交互.

在GO语言官方FAQ中,有如下陈述:

为了尊重`mutex`,`sync`包实现了`mutex`.但我们希望GO语言的编程风格会激励人们尝试更高等级的技巧.尤其是考虑构建你的程序,**以便1次只有1个goroutine负责某个特定的数据**.

**不要通过共享内存进行通信.相反,通过通信来共享内存**.有数不清的关于GO语言核心团队的文章、讲座和访谈,相对于使用像`sync.Mutex`这样的原语,他们更加拥护CSP.

有人抱怨过度使用channel,GO语言的维基上有一个关于此话题的引用:

GO语言的一个座右铭是,**"使用通信来共享内存,而不是通过共享内存来通信"**.

也就是说,GO语言确实在`sync`包中提供了传统的锁机制.大多数的锁问题都可以通过channel或者传统的锁,这两者之一来解决.

所以我应该用哪个?

**使用最好描述的和最简单的那个方式**.

我们主要的区分方式来自于**试图管理并发的地方**:主观地想象一个狭窄的范围,或者在我们的系统外部.

![决策树](../img/chapter2/决策树.jpg)

逐步介绍这些决策:

- 你想要转让数据的所有权吗?

**如果你有一块代码,这块代码产生一个计算结果,且你想共享这个结果给其他代码块,那么你实际上做的事情就是传递了数据的所有权**.也可以理解为:数据的所有者,使并发程序安全的一种方法是确保只有1个并发上下文拥有数据的所有权.而channel通过将这个意图编写进channel类型本身,来帮助我们表达这个意图.

这么做的一个很大的好处是:**可以创建一个带有缓冲区的channel,在在内存中实现一个低成本的队列,以便解耦生产者与消费者**;另一个好处在于:**使用channel确保你的并发代码可以和其他并发代码进行组合**.

- 你是否试图在保护某个结构的内部状态?

这种场景下,同步原语就是个很好的选择,也是你不该使用channel的一个很好的示例.**通过使用内存访问同步原语,你可以对调用者隐藏关于重要代码块的实现细节**.以下例子既线程安全,且不会给调用者带来复杂性:

```go
type Counter struct {
	mu sync.Mutex
	data int
}

func (c *Counter) Increment()  {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.data++
}
```

可以认为我们在这里所做的即使定义了`Counter`类型的原子性范围.`Increment()`可以被认为是原子的.

**记住这里的关键词是"内部的"如果你发现自己正在将锁暴露在一个类型之外,那么你就应该注意了.尽量将锁限制在一个小的范围内**.

****

个人理解:

我们之前有过这样一段代码:

```go
package main

import (
	"fmt"
	"sync"
)

func main() {
	var memoryAccess sync.Mutex

	var data int

	go func() {
		memoryAccess.Lock()
		data++
		memoryAccess.Unlock()
	}()

	memoryAccess.Lock()
	if data == 0 {
		fmt.Printf("the value is %v\n", data)
	} else {
		fmt.Printf("the value is %v\n", data)
	}
	memoryAccess.Unlock()
}
```

就应该改为:

```go
package main

import (
	"fmt"
	"sync"
)

type Data struct {
	mu sync.Mutex
	data int
}

func (d *Data) Increment() {
	d.mu.Lock()
	defer d.mu.Unlock()
	d.data++
}

func main() {
	var data Data = Data{
		mu: sync.Mutex{},
		data: 0,
	}

	go func() {
		data.Increment()
	}()

	if data.data == 0 {
		fmt.Printf("the value is %v\n", data.data)
	} else {
		fmt.Printf("the value is %v\n", data.data)
	}
}
```

****

- 你是否试图协调多个逻辑片段?

**channel本质上比内存访问同步原语更具有可组合性**.将锁分散在各个结构体中听起来像是一场噩梦,但是将channel编写的随处可见是被鼓励的.channel可以被组合,但是锁或者有返回值的方法很难被组合.

因为:

- GO的select语句
- channel可以当做队列使用
- channel线程安全

所以,使用channel可以更简单的控制你软件中激增的复杂性.**如果你发现正在挣扎着理解你的并发代码是如何工作的,为什么会出现死锁以及竞争,而你正在只用原语时,可能这是一个你应该切换到channel的好信号**.

- 这是一个对性能要求很高的临界区吗?

这并不表示"我想让我的程序拥有高性能,因此,我应该只是用`mutex`".反之,如果你有一部分程序,经过分析后,且事实证明它是一个主要瓶颈,且你发现这里比程序中的其他部分慢一些时,那么使用同步原语可以帮助这个关键部分在负载下执行.**这是因为channel使用内存访问同步来操作,因此它们只能更慢.但是,在我们考虑这一点之前,性能至关重要的程序部分,可能暗示我们需要重新规划我们的程序**.

Go语言的并发性哲学可以这样总结:**追求简洁,尽量使用channel,并且认为goroutine的使用是没有成本的**.